defaults:
  - override hydra/launcher: submitit_slurm

hparams:
  device: "cuda"

  tokenizer_model: "meta-llama/Llama-3.2-3B-Instruct"
  model: "../models/finetuned/llama3/"
  checkpoint: "checkpoint-1250"

  system_prompt: You are a helpful assistant.
  date_string: "10 Apr 2025"

  max_length: 200
  batch_size_inference: 200
  full_eval: False

  unlearning: True
  unlearning_loss: "pmc"
  pmc_selection: "rouge_reward"

  lambda_unlearning: 1.25
  top_p: 0.95
  temperature: 0.9
  num_samples: 20
  num_epochs: 15
  min_len: 5

  align: True
  lambda_alignment: 0.5
  alignment_responses: [
    "This information is not available.",
    "This information is not available at this time.",
    "Specific details are not available.",
    "Specific details are not available at this time.",
    "I don't have that information.",
    "I don't have that information available.",
    "I don't have that information at the moment.",
    "I don't have that information right now.",
    "I don't have that data.",
    "I don't have that data available.",
    "I don't have that data at the moment.",
    "I don't have that data right now.",
    "I'm sorry, I don't have that information.",
    "I'm sorry, I don't have that information available.",
    "I'm sorry, I don't have that information at the moment.",
    "I'm sorry, I don't have that information right now.",
    "I'm sorry, I don't have that data.",
    "I'm sorry, I don't have that data available.",
    "I'm sorry, I don't have that data at the moment.",
    "I'm sorry, I don't have that data right now.",
  ]

  batch_size: 8
  gradient_accumulation_steps: 2
  learning_rate: 1e-5
  weight_decay: 0.01
  gradient_checkpointing: True

  save_model: True
  seed: 0
  split: 10
  logging: False

hydra:  
  sweep:
    dir: ../models/aligned/llama3/${hparams.seed}/
    subdir: . 

  launcher:
    submitit_folder: ../models/aligned/llama3/submitit
    timeout_min: 80
    gres: gpu:1
    mem_gb: 40
    partition: gpu_h100
    qos: default
    cpus_per_task: 1
    tasks_per_node: 1
    name: PMC-align-llama3
    _target_: hydra_plugins.hydra_submitit_launcher.submitit_launcher.SlurmLauncher
    signal_delay_s: 0
    max_num_timeout: 0